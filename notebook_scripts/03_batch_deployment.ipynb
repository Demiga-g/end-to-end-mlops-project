{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlops.project_libraries import *\n",
    "from mlops.util_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in AWS profile\n",
    "os.environ[\"AWS_PROFILE\"] = \"demiga-g\"\n",
    "\n",
    "# Setting tracking uri (unique resource identifier)\n",
    "TRACKING_SERVER_HOST =  '127.0.0.1'  # '16.171.136.194'\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "# mlflow.set_experiment(\"model-vectorizer-as-one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "new_data = pd.read_csv('../data/val_df1.csv')\n",
    "\n",
    "# scrub the data\n",
    "df = scrub_data(new_data).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/midega-g/anaconda3/envs/ifood_mlops/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 137.40it/s] \n"
     ]
    }
   ],
   "source": [
    "# get the model\n",
    "BASE_LOCATION = 'mlflow-artifacts:' # 's3://midega-mlflow-artifacts'\n",
    "EXPERIMENT_ID = 6\n",
    "RUN_ID = '45a3990ff1e140afbe48334a8422bec7'\n",
    "logged_model = f'{BASE_LOCATION}/{EXPERIMENT_ID}/{RUN_ID}/artifacts/model'\n",
    "model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data in a dataframe\n",
    "df_result = pd.DataFrame()\n",
    "df_result['ID'] = new_data['ID']\n",
    "df_result['PredictedResponse'] = y_pred\n",
    "df_result['ModelVersion'] = RUN_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results with actual responses\n",
    "df_result['ActualResponse'] = new_data['Response']\n",
    "df_result['PredictionStatus'] = ((df_result['PredictedResponse'] == df_result['ActualResponse'])\n",
    "                                 .map({True: \"Correct\", False: \"Incorrect\"}))\n",
    "overall_accuracy = df_result['PredictionStatus'].value_counts(normalize=True)\n",
    "positive_response_accuracy = len(df_result[(df_result['PredictedResponse']==1) & \n",
    "                                       (df_result['ActualResponse']== 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Correct      0.693069\n",
       "Incorrect    0.306931\n",
       "Name: PredictionStatus, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_response_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    563\n",
       "1     43\n",
       "Name: ActualResponse, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['ActualResponse'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ifood_mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
